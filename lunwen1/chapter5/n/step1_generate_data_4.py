import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import os
import glob
import numpy as np
import pandas as pd
import warnings
from scipy.signal import savgol_filter
from lunwen1.chapter5.bayes_imm.online_optimizer import OnlineBoOptimizer
from lunwen1.chapter5.bayes_imm.imm_lib_enhanced import IMMFilterEnhanced  # [æ–°å¢] éœ€è¦å¼•å…¥ IMM

# ================= é…ç½® =================
DATA_FOLDER = r'D:\AFS\lunwen\dataSet\processed_data_4'
OUTPUT_DATA_FILE = '../network/npz_n/5/training_data_part5.npz'

EXCLUDED_FILES = [
]

REPEAT_PER_FILE = 3  # æ¯ä¸ªæ–‡ä»¶é‡å¤æ¬¡æ•°
WINDOW_SIZE = 90  # è§‚æµ‹çª—å£
OPTIMIZE_INTERVAL = 20
DT = 1 / 30
NOISE_STD = 5.0

SAVGOL_WINDOW = 25
SAVGOL_POLY = 2

def setup_seed(seed):
    np.random.seed(seed)
    print(f">>> éšæœºç§å­å·²å›ºå®šä¸º: {seed}")

def load_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df.columns = df.columns.str.strip()
        required_cols = ['x', 'y', 'z']  # åªéœ€è¦ä½ç½®çœŸå€¼å³å¯
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            print(f"  [è·³è¿‡] ç¼ºåˆ—: {missing} in {os.path.basename(filepath)}")
            return None
        return df[required_cols].values
    except Exception as e:
        print(f"  [é”™è¯¯] {os.path.basename(filepath)}: {e}")
        return None


def calculate_derivatives(pos_data, dt):
    """
    [ä¿®æ”¹2] ä½¿ç”¨ Savitzky-Golay æ»¤æ³¢å™¨è®¡ç®—é€Ÿåº¦å’ŒåŠ é€Ÿåº¦ã€‚
    åŸä»£ç ä½¿ç”¨ç®€å•å·®åˆ† (pos[k]-pos[k-1])/dt ä¼šå¯¼è‡´å™ªå£°æ”¾å¤§30å€(é€Ÿåº¦)å’Œ900å€(åŠ é€Ÿåº¦)ã€‚
    """
    # å¦‚æœæ•°æ®å¤ªçŸ­æ— æ³•æ»¤æ³¢ï¼Œå›é€€åˆ°åŸæ¥çš„é€»è¾‘ï¼ˆé˜²æ­¢æŠ¥é”™ï¼‰
    if len(pos_data) < SAVGOL_WINDOW:
        vel = np.zeros_like(pos_data)
        vel[1:] = (pos_data[1:] - pos_data[:-1]) / dt
        vel[0] = vel[1]

        acc = np.zeros_like(pos_data)
        acc[1:] = (vel[1:] - vel[:-1]) / dt
        acc[0] = acc[1]
        return vel, acc

    # deriv=1 ç®—ä¸€é˜¶å¯¼(é€Ÿåº¦), deriv=2 ç®—äºŒé˜¶å¯¼(åŠ é€Ÿåº¦)
    # delta=dt è‡ªåŠ¨å¤„ç† /dt çš„ç¼©æ”¾
    vel = savgol_filter(pos_data, window_length=SAVGOL_WINDOW, polyorder=SAVGOL_POLY,
                        deriv=1, delta=dt, axis=0)
    acc = savgol_filter(pos_data, window_length=SAVGOL_WINDOW, polyorder=SAVGOL_POLY,
                        deriv=2, delta=dt, axis=0)

    return vel, acc


def process_single_trajectory(raw_data, file_id):
    """
    [ä¿®å¤ç‰ˆ] å¢åŠ äº† float64 ç²¾åº¦è½¬æ¢å’Œ try-except å¼‚å¸¸æ•è·ï¼Œé˜²æ­¢ Cholesky æŠ¥é”™ä¸­æ–­ã€‚
    """
    X_list = []
    Y_list = []
    G_list = []  # [æ–°å¢] å­˜å‚¨ç»„ID

    pos_gt = raw_data[:, :3]  # çœŸå€¼
    n_steps = len(pos_gt)

    if n_steps <= WINDOW_SIZE + 20:
        return [], [], []

    # === å¾ªç¯é‡å¤ç”Ÿæˆ ===
    for rep in range(REPEAT_PER_FILE):
        # 1. ç”Ÿæˆå¸¦å™ªè§‚æµ‹
        noise = np.random.normal(0, NOISE_STD, pos_gt.shape)
        pos_measured = pos_gt + noise

        # 2. åˆå§‹åŒ– IMM
        initial_trans = np.array([[0.81388511, 0.18511489, 0.001], [0.989, 0.01, 0.001], [0.01, 0.01, 0.98]])
        init_state = np.zeros(9)
        init_state[0] = pos_measured[0, 0]
        init_state[3] = pos_measured[0, 1]
        init_state[6] = pos_measured[0, 2]
        init_state[1] = 265.0  # ç²—ç•¥é€Ÿåº¦

        # åæ–¹å·®åˆå§‹åŒ–
        init_cov_diag = np.zeros(9)
        init_cov_diag[[0, 3, 6]] = 100.0
        init_cov_diag[[1, 4, 7]] = 25.0
        init_cov_diag[[2, 5, 8]] = 10.0
        init_cov = np.diag(init_cov_diag)

        r_cov = np.eye(3) * (NOISE_STD ** 2)

        # å®ä¾‹åŒ– IMM å’Œ ä¼˜åŒ–å™¨
        imm = IMMFilterEnhanced(initial_trans, init_state, init_cov, r_cov=r_cov)
        optimizer = OnlineBoOptimizer(imm, DT)

        default_params = [0.98, 0.01, 0.01, 0.98, 0.01, 0.01]
        current_params = default_params

        # 3. è¿è¡Œæ»¤æ³¢å¾ªç¯
        for k in range(n_steps):
            z_k = pos_measured[k]

            # (A) è®°å½•å½“å‰æ—¶åˆ»çš„æ•°æ®ç”¨äºç”Ÿæˆç‰¹å¾
            if k >= WINDOW_SIZE and k % OPTIMIZE_INTERVAL == 0:
                if k + WINDOW_SIZE <= n_steps:
                    # 1. å‡†å¤‡ç‰¹å¾æ•°æ®
                    hist_pos = pos_measured[k - WINDOW_SIZE: k]
                    hist_vel, hist_acc = calculate_derivatives(hist_pos, DT)
                    rel_pos = hist_pos - hist_pos[-1]
                    features = np.hstack([rel_pos, hist_vel, hist_acc])

                    # 2. å‡†å¤‡ä¼˜åŒ–æ‰€éœ€æ•°æ®
                    snapshot = imm.get_state_snapshot()

                    # [å…³é”®ä¿®å¤ 1] å¼ºåˆ¶è½¬æ¢ä¸º float64ï¼Œæé«˜çŸ©é˜µåˆ†è§£çš„ç¨³å®šæ€§
                    future_window = pos_gt[k:k + WINDOW_SIZE].T.astype(np.float64)
                    # future_window = pos_measured[k:k + WINDOW_SIZE].T.astype(np.float64)

                    best_p = None
                    # [å…³é”®ä¿®å¤ 2] å¢åŠ  try-except æ•è· Cholesky/Numerical é”™è¯¯
                    try:
                        # æš‚æ—¶æŠ‘åˆ¶é‚£çƒ¦äººçš„è­¦å‘Šï¼Œæˆ–è€…è®©å®ƒæŠ¥é”™ä»¥ä¾¿æ•è·
                        with warnings.catch_warnings():
                            warnings.simplefilter("ignore")  # å¿½ç•¥è­¦å‘Šç»§ç»­è¿è¡Œ

                            best_p = optimizer.run_optimization(
                                future_window,
                                snapshot,
                                current_params,
                                default_params,
                                n_iter=5
                            )
                    except Exception as e:
                        print(f"  [è­¦å‘Š] Frame {k} ä¼˜åŒ–å¤±è´¥ (è·³è¿‡): {e}")
                        best_p = None

                    if best_p is not None:
                        # è½¬ numpy æ–¹ä¾¿æ£€æŸ¥
                        best_p_arr = np.array(best_p, dtype=np.float32)

                        # æ£€æŸ¥1: æ˜¯å¦å…¨ä¸ºæœ‰é™æ•° (é NaN, é Inf)
                        is_finite = np.all(np.isfinite(best_p_arr))

                        # æ£€æŸ¥2: (å¯é€‰) æ˜¯å¦åœ¨ [0, 1] èŒƒå›´å†…
                        # è™½ç„¶ Sigmoid ä¼šå¤„ç†ï¼Œä½†å¦‚æœä¼˜åŒ–å™¨è·‘å‡º 1e10 è¿™ç§æ•°ä¹Ÿæ˜¯ä¸æ­£å¸¸çš„
                        is_in_range = np.all((best_p_arr >= 0.0) & (best_p_arr <= 1.0))

                        if is_finite and is_in_range:
                            # åªæœ‰æ•°æ®å®Œå…¨å¹²å‡€ï¼Œæ‰åŠ å…¥æ•°æ®é›†
                            X_list.append(features.astype(np.float32))
                            Y_list.append(best_p_arr)
                            G_list.append(file_id)  # [æ–°å¢] è®°å½•å½“å‰æ ·æœ¬å±äºå“ªä¸ªæ–‡ä»¶

                            # æ›´æ–°ä¸‹ä¸€è½®ä¼˜åŒ–çš„èµ·ç‚¹
                            current_params = best_p

                            # æ›´æ–° IMM çŸ©é˜µï¼Œç»§ç»­è·Ÿè¸ª
                            new_mtx = optimizer.construct_matrix_static(best_p)
                            imm.set_transition_matrix(new_mtx)
                        else:
                            # å³ä½¿ç®—å‡ºäº†ç»“æœï¼Œå¦‚æœç»“æœæ˜¯ NaN æˆ–ç¦»è°±å€¼ï¼Œè§†ä¸ºä¼˜åŒ–å¤±è´¥
                            # print(f"  [è¿‡æ»¤] Frame {k} äº§ç”Ÿæ— æ•ˆå‚æ•° (NaN/Inf): {best_p}")
                            # ä¸æ›´æ–° current_paramsï¼Œä¿æŒä¸Šä¸€æ¬¡çš„å‚æ•°ï¼Œé˜²æ­¢é›ªå´©
                            pass

            # (B) IMM æ­¥è¿›
            imm.update(z_k, DT)

    return X_list, Y_list, G_list


def main():
    setup_seed(42)

    print("=== Step 1: ç”Ÿæˆå¢å¼ºè®­ç»ƒæ•°æ® (ä¿®æ­£é—­ç¯ç‰ˆ) ===")
    search_path = os.path.join(DATA_FOLDER, "*.csv")
    csv_files = glob.glob(search_path)

    # ... (åç»­ä¸»å¾ªç¯ä»£ç ä¸æ‚¨ä¹‹å‰çš„ä¸€è‡´ï¼Œä¿æŒä¸å˜å³å¯) ...
    # åªè¦ç¡®ä¿ process_single_trajectory è¢«æ›¿æ¢å³å¯

    if not csv_files:
        print(f"åœ¨ {DATA_FOLDER} æœªæ‰¾åˆ° CSV æ–‡ä»¶")
        return

    all_X = []
    all_Y = []
    all_G = []  # [æ–°å¢]
    skipped_count = 0

    for f_idx, filepath in enumerate(csv_files):
        filename = os.path.basename(filepath)
        if filename in EXCLUDED_FILES:
            print(f"[{f_idx + 1}/{len(csv_files)}] ğŸš« è·³è¿‡æµ‹è¯•é›†: {filename}")
            skipped_count += 1
            continue

        print(f"[{f_idx + 1}/{len(csv_files)}] å¤„ç†è®­ç»ƒé›†: {filename}")
        raw_data = load_data(filepath)
        if raw_data is None: continue

        x_batch, y_batch, g_batch = process_single_trajectory(raw_data, f_idx)
        if len(x_batch) > 0:
            all_X.extend(x_batch)
            all_Y.extend(y_batch)
            all_G.extend(g_batch)  # [æ–°å¢]
            print(f"  > ç”Ÿæˆæ ·æœ¬ {len(x_batch)} ä¸ª")

    # ä¿å­˜éƒ¨åˆ†
    if not all_X:
        print("æœªç”Ÿæˆæ•°æ®ã€‚")
        return

    all_X = np.array(all_X, dtype=np.float32)
    all_Y = np.array(all_Y, dtype=np.float32)
    all_G = np.array(all_G, dtype=np.int32)  # [æ–°å¢]

    print("-" * 30)
    print(f"ç”Ÿæˆå®Œæ¯•ã€‚X: {all_X.shape}, Y: {all_Y.shape}, G: {all_G.shape}")
    np.savez(OUTPUT_DATA_FILE, X=all_X, Y=all_Y, G=all_G)
    print(f"æ•°æ®å·²ä¿å­˜è‡³ {OUTPUT_DATA_FILE}")


if __name__ == '__main__':
    main()